{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9de7580",
   "metadata": {},
   "source": [
    "# Regression and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df010de0",
   "metadata": {},
   "source": [
    "Simple Linear Regression provides a model of the relationship between the magnitude of one variable with another.\n",
    "Correlation is another way to measure how two variables are related. \n",
    "Correlation measures the strength of an association between two variables, Regression quantifies the nature of the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "model =  LinearRegression().fit(X, Y) # X->independent variable, Y->dependent variable\n",
    "print(f'Intercept: {model.intercept_:.3f}')\n",
    "print(f'Coefficient Exposure: {model.coef_[0]:.3f}')\n",
    "\n",
    "fitted = model.predict(X)\n",
    "residuals = y - fitted\n",
    "print(\"FINAL MODEL R_SQUARE: \",r2_score(Y, fitted))  #R2 measures the proportion of variation in data\n",
    "print(fitted.summary())\n",
    "\n",
    "#For Multilinear Regression There will be multiple input/indipendent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d90dc3",
   "metadata": {},
   "source": [
    "The most important performance metric is root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262511bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(Y, fitted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b589e4",
   "metadata": {},
   "source": [
    "The t-statistic and the p-value measures the extent to which a coefficient is \"statistically significant\". the higher the t-statistic and lower the p-value, the more significant the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = fitted.summary2().tables[1]['P>|t|']\n",
    "\n",
    "print(fitted.fit().f_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccce3e7",
   "metadata": {},
   "source": [
    "Model Selection and Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to convert the categorical and boolean variables into numbers\n",
    "columns=['column1','column2']\n",
    "X = pd.get_dummies(df[columns], drop_first=True)\n",
    "\n",
    "#Uswe statsmodels to get a more detailed analysis of the regression model\n",
    "\n",
    "model = sm.OLS(Y, X.assign(const=1))\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikiT-LEARN HAS NO IMPLEMENTATION FOR STEPWISE REGRESSION. We implement functions stepwise_selection, forward_selectio, and backward_elimination in our package\n",
    "#Stepwise regression is a way to automatically determine which variable should be included in the model.\n",
    "\n",
    "#Define a function that returns a fitted model for a given set of variables.\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(X[variavles], y)\n",
    "    return model\n",
    "\n",
    "#Define a function that returns a score for a given model and set of variables. In this case, we use the AIC_score implementation in the dnba package.\n",
    "def score_model(model, variables):\n",
    "    if len(variables) ==0:\n",
    "        return AIC_score(y, [y.mean()] * len(y), model, df=1)\n",
    "    return AIC_score(y, model.predict(X[Variables]), model)\n",
    "\n",
    "best_model, best_variables = stepwise_selection(X.columns, train_model, score_model, verbose=True)\n",
    "\n",
    "print(f'Intercept: {best_model.intercept_:.3f}')\n",
    "print(f'Coefficient Exposure: ')\n",
    "for name, coef in zip(best_variables, best_model.coef_):\n",
    "    print(f' {name}: {coef}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighted Regression\n",
    "#1. Inverse-variance weighting when different observations have been measured with different precision, the higher variance ones recieving lower weight\n",
    "#2. Analysis of data where rows represent multiple cases, the weight variable encodes how many original observations each row represents.\n",
    "\n",
    "model.fit(X, Y, sample_weight=df.Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bootstrapping:  Drawing additional samples with replacement from the sample itself and recalculate the statistic or model for each resample.\n",
    "# The useful metrics for varible selection are confidence intervals, which are uncertainty intervals placed around regression coefficients and predictions.An easy way to understand this is via the bootstrap.\n",
    "\n",
    "results = []\n",
    "for n in range(1000):\n",
    "    sample = resample(loans_income)\n",
    "    resulits.append(sample.median())\n",
    "results = pd.Series(results)\n",
    "print('Bootstrap Statistics: ')\n",
    "print(f'original: {loans_income.median()}')\n",
    "print(f'bias: {results.mean() - loans_income.median()}')\n",
    "print(f'std. error: {results.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dde7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Factor Variables in Regression\n",
    "# The most common approach is to convert a variable into a set of binary dummy variables.\n",
    "pd.get_dummies(df['list of columns'], drop_first=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
